{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/7a/fd8059a3881d3ab37ac8f72f56b73937a14e8bb14a9733e68cc8b17dbe3c/bayesian-optimization-1.2.0.tar.gz\n",
      "Requirement already satisfied: numpy>=1.9.0 in /Users/liuchuqiao/opt/anaconda3/lib/python3.7/site-packages (from bayesian-optimization) (1.17.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in /Users/liuchuqiao/opt/anaconda3/lib/python3.7/site-packages (from bayesian-optimization) (1.3.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in /Users/liuchuqiao/opt/anaconda3/lib/python3.7/site-packages (from bayesian-optimization) (0.23.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/liuchuqiao/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/liuchuqiao/opt/anaconda3/lib/python3.7/site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.13.2)\n",
      "Building wheels for collected packages: bayesian-optimization\n",
      "  Building wheel for bayesian-optimization (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-cp37-none-any.whl size=11686 sha256=f1f2b682f32cc7543b2af837a6c116d8a1632ed80c3e63e69292ee8e7f6031da\n",
      "  Stored in directory: /Users/liuchuqiao/Library/Caches/pip/wheels/5a/56/ae/e0e3c1fc1954dc3ec712e2df547235ed072b448094d8f94aec\n",
      "Successfully built bayesian-optimization\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bayesian optimization\n",
    "def bayesian_optimization(dataset, function, parameters):\n",
    "   X_train, y_train, X_test, y_test = dataset\n",
    "   n_iterations = 5\n",
    "   gp_params = {\"alpha\": 1e-4}\n",
    "\n",
    "   BO = BayesianOptimization(function, parameters)\n",
    "   BO.maximize(n_iter=n_iterations, **gp_params)\n",
    "\n",
    "   return BO.max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_optimization(cv_splits):\n",
    "    def function(n_estimators, max_depth, min_samples_split):\n",
    "        return cross_val_score(\n",
    "               RandomForestRegressor(\n",
    "                   n_estimators=int(max(n_estimators,0)),                                                               \n",
    "                   max_depth=int(max(max_depth,1)),\n",
    "                   min_samples_split=int(max(min_samples_split,2)), \n",
    "                   n_jobs=-1, \n",
    "                   random_state=42,   \n",
    "                   class_weight=\"balanced\"),  \n",
    "               X=X_train, \n",
    "               y=y_train, \n",
    "               cv=cv_splits,\n",
    "               scoring=\"roc_auc\",\n",
    "               n_jobs=-1).mean()\n",
    "\n",
    "    parameters = {\"n_estimators\": (10, 1000),\n",
    "                  \"max_depth\": (1, 150),\n",
    "                  \"min_samples_split\": (2, 10)}\n",
    "    \n",
    "    return function, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_optimization(cv_splits, eval_set):\n",
    "    def function(eta, gamma, max_depth):\n",
    "            return cross_val_score(\n",
    "                   xgb.XGBClassifier(\n",
    "                       objective=\"binary:logistic\",\n",
    "                       learning_rate=max(eta, 0),\n",
    "                       gamma=max(gamma, 0),\n",
    "                       max_depth=int(max_depth),                                               \n",
    "                       seed=42,\n",
    "                       nthread=-1,\n",
    "                       scale_pos_weight = len(y_train[y_train == 0])/\n",
    "                                          len(y_train[y_train == 1])),  \n",
    "                   X=X_train, \n",
    "                   y=y_train, \n",
    "                   cv=cv_splits,\n",
    "                   scoring=\"roc_auc\",\n",
    "                   fit_params={\n",
    "                        \"early_stopping_rounds\": 10, \n",
    "                        \"eval_metric\": \"auc\", \n",
    "                        \"eval_set\": eval_set},\n",
    "                   n_jobs=-1).mean()\n",
    "\n",
    "    parameters = {\"eta\": (0.001, 0.4),\n",
    "                  \"gamma\": (0, 20),\n",
    "                  \"max_depth\": (1, 2000)}\n",
    "    \n",
    "    return function, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "n = 5\n",
    "X_train = [0]*n\n",
    "X_test =[0]*n\n",
    "y_train = [0]*n\n",
    "y_test = [0]*n\n",
    "\n",
    "for i in range(0,n):\n",
    "    data = datasets.make_friedman1(n_samples = 100, n_features = 5, noise = 1)\n",
    "    X_train[i] = data[0][0:50]\n",
    "    X_test[i] = data[0][50:data[0].shape[0]]\n",
    "    y_train[i] = data[1][0:50]\n",
    "    y_test[i] = data[1][50:data[1].shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train model\n",
    "def train(X_train, y_train, X_test, y_test, function, parameters):\n",
    "    dataset = (X_train, y_train, X_test, y_test)\n",
    "    cv_splits = 4\n",
    "    \n",
    "    best_solution = bayesian_optimization(dataset, function, parameters)      \n",
    "    params = best_solution[\"params\"]\n",
    "\n",
    "    model = RandomForestRegressor(\n",
    "             n_estimators=int(max(params[\"n_estimators\"], 0)),\n",
    "             max_depth=int(max(params[\"max_depth\"], 1)),\n",
    "             min_samples_split=int(max(params[\"min_samples_split\"], 2)), \n",
    "             n_jobs=-1, \n",
    "             random_state=42,   \n",
    "             class_weight=\"balanced\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-b729bf31951b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbayesian_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrfc_optimization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'function' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
