{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7.45443878 18.20545887 14.29400891  9.65617145 22.26487029 11.47963127\n",
      " 14.50143885 19.58439488 20.30382531 14.94661972 19.84599292  9.27833302\n",
      " 19.96675609 14.63633634 16.17152365 20.02751325 14.70198061  8.88761479\n",
      " 12.73228913 15.76980523 13.14219048 11.88601634  5.23995084 24.21183636\n",
      " 13.26483603  8.43047168 17.35215613 15.26868895 18.88254206 18.33654641\n",
      " 14.11605463 14.75640954 17.37602207 18.12867095 21.62500225 10.94069684\n",
      " 13.87958255 17.14271621  7.21356191 15.28969153 18.38754072  9.40632669\n",
      " 21.91981466 20.65502941 18.54783029 14.21785228 12.55765436 13.15362201\n",
      " 23.10724182 19.31400173]\n",
      "------------------------\n",
      "[11.37693192 19.48713996  6.07536094 15.34019917 15.40141604 16.33636479\n",
      " 13.03746092  6.1614286  15.85295718 17.1846833  17.76957281  6.33278556\n",
      " 13.36600689 13.95482638 23.2925214  15.01873548 10.59640591 15.18732858\n",
      " 11.73482133 19.21731511 15.7512567  10.30065695 16.51926427  5.88677761\n",
      " 10.28390155 11.78253899  4.66173275 17.17681508 14.04245463 27.83254581\n",
      " 14.66069589 18.424871   15.20576105 20.56855088 19.54845368 15.47947413\n",
      " 10.91910304 16.79823592 23.92558236 22.42948965  8.51426683 11.03757662\n",
      " 12.14845317 12.93825002 20.0281797   7.29590686 10.21402939 13.81761198\n",
      " 16.75529749 17.91769969]\n",
      "------------------------\n",
      "[19.32259418 13.32113687 17.32868328  3.17211927 12.51074641 13.59258974\n",
      " 14.7552196  23.73486868 15.34781418 10.80793969  7.35014949 12.18996026\n",
      " 22.93368552 12.30507625 20.10988054 15.04117539 15.52794221  8.88750471\n",
      " 18.88351279 12.50278775 22.72014443 12.37577015 19.7671251  12.95252032\n",
      "  3.15411096 10.76094072 11.8432503   9.36263105  9.4743613  16.32768778\n",
      " 12.51256687 12.18576798 20.81414234 12.90782364 15.04677787 16.71883988\n",
      " 18.92739965 12.10214241  9.63103215 19.38129973 10.9545922  21.82685901\n",
      " 20.93718939 16.13084515 14.06131971 14.69566458 15.71995306  7.20690318\n",
      " 24.52831015  5.36035937]\n",
      "------------------------\n",
      "[13.01194161 20.42898671  8.5375788  11.13558758 21.30905194 16.4274854\n",
      " 12.65953162 13.52817039 14.72937266 12.57152104 17.89542778 25.55175156\n",
      " 10.90924486 19.71431742  9.68128448 17.94233609  9.38525111  8.45651757\n",
      " 10.07720105 13.82393757  9.46276222 18.5966469  25.86026562 16.98403904\n",
      " 10.33564122 13.53143205 17.0245106  14.78457738 10.09233809  9.00422079\n",
      " 16.93045438 13.18246259 11.48555826 12.98165433 13.80465695 14.62256964\n",
      " 16.60222211  4.73249158  8.39340293 18.17503906 16.4976996  18.64217346\n",
      " 27.2805737  11.11558245  4.25657815  2.43995725 16.33736123 15.93322475\n",
      " 20.91238155 13.37556962]\n",
      "------------------------\n",
      "[16.79155895 21.25871218 14.8084908  19.05498856 11.37385818  5.98960106\n",
      " 17.30305776 16.54234942 20.64605993 11.28824982  9.06551561 11.87899566\n",
      " 12.16191151  9.27264376 16.31637826  3.52920301 10.0603681   3.02690235\n",
      " 11.45913775  9.16871581  8.65311991 12.45443507 19.42476499 18.88001441\n",
      " 18.65575623 20.62549493 13.38722293 17.10400137 17.42968821 21.40348638\n",
      " 22.11886772 19.42696816 14.17673467 17.82829356 14.8858847   6.30335919\n",
      " 20.25324222  8.88882414  8.69820404 13.12659791 20.8252053   9.31311856\n",
      " 15.45297699 10.9035142  12.78648934 12.10809345 19.49183711 17.7150646\n",
      " 10.31345124 15.91862654]\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "n = 5\n",
    "x_train = [0]*n\n",
    "x_test =[0]*n\n",
    "y_train = [0]*n\n",
    "y_test = [0]*n\n",
    "\n",
    "for i in range(0,n):\n",
    "    data = datasets.make_friedman1(n_samples = 100, n_features = 5, noise = 1)\n",
    "    x_train[i] = data[0][0:50]\n",
    "    x_test[i] = data[0][50:data[0].shape[0]]\n",
    "    y_train[i] = data[1][0:50]\n",
    "    y_test[i] = data[1][50:data[1].shape[0]]\n",
    "    \n",
    "for i in range(0,n):\n",
    "    print(y_test[i])\n",
    "    print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [5, 50]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c24c5369c542>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mresults_gs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'in-score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mgs_pred_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mresults_gs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'out-score'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs_pred_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mresults_gs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m    253\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 254\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    255\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \"\"\"\n\u001b[1;32m---> 84\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    255\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[1;32m--> 257\u001b[1;33m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[0;32m    258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [5, 50]"
     ]
    }
   ],
   "source": [
    "#compare grid and random search. search over all combinations. random forest\n",
    "\n",
    "'''\n",
    "note that, for random forest:\n",
    "n_estimators = num.trees\n",
    "min_samples_leaf = min.node.size\n",
    "max_features = mtry\n",
    "max_samples = sample.fraction\n",
    "'''\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time\n",
    "\n",
    "par_grid = {'n_estimators':[1,2,3,4,5], \n",
    "        'min_samples_leaf':np.linspace(0.1,0.5,5), \n",
    "        'max_features':np.linspace(0.1,0.5,5), \n",
    "        'max_samples':np.linspace(0.1,0.5,5)}\n",
    "\n",
    "results_rs = pd.DataFrame(np.zeros((n,4)), columns = ['out-score', 'in-score', 'time', 'params'])\n",
    "results_gs = pd.DataFrame(np.zeros((n,4)), columns = ['out-score', 'in-score', 'time', 'params'])\n",
    "\n",
    "for i in range(0,n):\n",
    "    gs = model_selection.GridSearchCV(estimator = RandomForestRegressor(), \n",
    "                                      param_grid = par_grid, \n",
    "                                      scoring = 'neg_root_mean_squared_error', \n",
    "                                      cv = 3)\n",
    "    \n",
    "    start = time.thread_time()\n",
    "    gs.fit(x_train[i], y_train[i])\n",
    "    stop = time.thread_time()\n",
    "    \n",
    "    results_gs.loc[i, 'params'] = str(gs.best_params_)\n",
    "    results_gs.loc[i, 'in-score'] = gs.best_score_\n",
    "    gs_pred_i = gs.best_estimator_.predict(x_test[i])\n",
    "    results_gs.loc[i, 'out-score'] = math.sqrt(mean_squared_error(y_true = y_test, y_pred = gs_pred_i))\n",
    "    results_gs.loc[i, 'time'] = stop - start\n",
    "\n",
    "    rs = model_selection.RandomizedSearchCV(estimator = RandomForestRegressor(), \n",
    "                                        param_distributions = par_grid,\n",
    "                                        n_iter = 5**4,\n",
    "                                        scoring = 'neg_root_mean_squared_error',\n",
    "                                        cv = 3)\n",
    "    \n",
    "    start = time.thread.time()\n",
    "    rs.fit(x_train[i], y_train[i])\n",
    "    stop = time.thread.time()\n",
    "    \n",
    "    results_rs.loc[i, 'params'] = str(rs.best_params_)\n",
    "    results_rs.loc[i, 'in-score'] = rs.best_score_\n",
    "    rs_pred_i = rs.best_estimator_.predict(x_test[i])\n",
    "    results_rs.loc[i, 'out-score'] = math.sqrt(mean_squared_error(y_true = y_test, y_pred = rs_pred_i))\n",
    "    results_rs.loc[i, 'time'] = stop - start\n",
    "    \n",
    "print(results_gs)\n",
    "print(results_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 3, 'min_samples_leaf': 0.4, 'max_samples': 0.5, 'max_features': 0.30000000000000004}\n",
      "{'n_estimators': 3, 'min_samples_leaf': 0.4, 'max_samples': 0.5, 'max_features': 0.30000000000000004}\n"
     ]
    }
   ],
   "source": [
    "#compare grid and random search. search along only 1 parameter at a time. random forest.\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import model_selection\n",
    "import time\n",
    "\n",
    "x = datasets.make_friedman1(n_samples = 50, n_features = 5, noise = 0)\n",
    "\n",
    "#I decided to define the default parameters as somewhere in the middle of the entire space\n",
    "def_pars = {'n_estimators':3, 'min_samples_leaf':0.3, 'max_samples':0.3, 'max_features':0.3}\n",
    "best_pars_gs = def_pars\n",
    "best_pars_rs = def_pars\n",
    "\n",
    "param_grid = {'n_estimators':[1,2,3,4,5], \n",
    "        'min_samples_leaf':np.linspace(0.1,0.5,5), \n",
    "        'max_features':np.linspace(0.1,0.5,5), \n",
    "        'max_samples':np.linspace(0.1,0.5,5)}\n",
    "space_sizes = {'n_estimators':5, 'min_samples_leaf':5, 'max_features':5, 'max_samples':5}\n",
    "\n",
    "for par in param_grid:\n",
    "    rf = RandomForestRegressor(n_estimators = def_pars['n_estimators'],\n",
    "                                min_samples_leaf = def_pars['min_samples_leaf'],\n",
    "                                max_samples = def_pars['max_samples'],\n",
    "                                max_features = def_pars['max_features']\n",
    "                               )\n",
    "    one_par = {par:param_grid[par]}\n",
    "    gs = model_selection.GridSearchCV(estimator = rf,\n",
    "                                      param_grid = one_par,\n",
    "                                      cv = 3,\n",
    "                                      scoring = 'neg_mean_squared_error'\n",
    "                                     )\n",
    "    gs.fit(x[0], x[1])\n",
    "    best_pars_gs[par] = gs.best_params_[par]\n",
    "    rs = model_selection.RandomizedSearchCV(estimator = rf,\n",
    "                                           param_distributions = one_par,\n",
    "                                           cv = 3,\n",
    "                                            n_iter = space_sizes[par],\n",
    "                                           scoring = 'neg_mean_squared_error')\n",
    "    rs.fit(x[0], x[1])\n",
    "    best_pars_rs[par] = rs.best_params_[par]\n",
    "\n",
    "print(best_pars_gs)\n",
    "print(best_pars_rs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
